<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Whispers of Atabey</title>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <style>
    html, body {
      height: 100%;
      margin: 0;
      padding: 0;
      display: flex;
      flex-direction: column;
    }

    body {
      font-family: Arial, sans-serif;
      background: linear-gradient(to bottom right, #f2f2f2, #d9d9d9);
      color: #333;
    }

    header, footer {
      padding: 1rem;
      text-align: center;
      background-color: white;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      position: relative;
    }

    header h1 {
      margin: 0;
      font-size: 2rem;
    }

    header .subtitle {
      font-size: 1.1rem;
      color: #555;
      margin-top: 0.5rem;
      max-width: 700px;
      margin: 0.5rem auto 0;
    }

    #homeBtn {
      position: absolute;
      top: 1rem;
      left: 1rem;
      padding: 0.4rem 0.8rem;
      font-size: 0.9rem;
      background-color: #007bff;
      color: white;
      border: none;
      border-radius: 6px;
      cursor: pointer;
    }

    #voiceChatPage {
      flex: 1;
    }

    .voice-wrapper {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100%;
      padding: 1rem;
    }

    #statusText {
      font-size: 1.2rem;
      margin-bottom: 1rem;
      color: #555;
    }

    #orb {
      position: relative;
      width: 120px;
      height: 120px;
      border-radius: 50%;
      background: radial-gradient(circle at center, #007bff, #004080);
      box-shadow: 0 0 20px rgba(0,123,255,0.5);
      cursor: pointer;
      transition: all 0.3s ease;
    }

    .orb.recording {
      background: radial-gradient(circle at center, #e60000, #800000);
      box-shadow: 0 0 30px 10px rgba(255, 0, 0, 0.6);
      animation: pulseRecording 1s infinite ease-in-out;
    }

    .orb.processing {
      background: radial-gradient(circle at center, #ffaa00, #aa5500);
      box-shadow: 0 0 20px rgba(255,170,0,0.6);
      animation: swirl 2s linear infinite;
    }

    .orb.speaking {
      background: radial-gradient(circle at center, #00ffd5, #008f75);
      box-shadow: 0 0 40px 20px rgba(0, 255, 213, 0.6), 0 0 60px 30px rgba(0, 255, 213, 0.3);
      animation: ripple 1.2s infinite ease-in-out;
    }

    .orb.speaking::after {
      content: '';
      position: absolute;
      width: 160px;
      height: 160px;
      border-radius: 50%;
      background: rgba(0, 255, 213, 0.2);
      animation: pulseRing 1.2s infinite;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: -1;
    }

    @keyframes pulseRecording {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.1); }
    }

    @keyframes swirl {
      0% { filter: hue-rotate(0deg); }
      100% { filter: hue-rotate(360deg); }
    }

    @keyframes ripple {
      0% { box-shadow: 0 0 10px 2px rgba(0,204,153,0.4); }
      50% { box-shadow: 0 0 20px 10px rgba(0,204,153,0.3); }
      100% { box-shadow: 0 0 10px 2px rgba(0,204,153,0.4); }
    }

    @keyframes pulseRing {
      0% { transform: translate(-50%, -50%) scale(1); opacity: 0.6; }
      100% { transform: translate(-50%, -50%) scale(1.8); opacity: 0; }
    }

    #debugOutput {
      margin-top: 1rem;
      font-size: 0.9rem;
      color: #666;
      max-width: 700px;
      text-align: center;
    }
  </style>
</head>
<body>
  <header>
    <h1>Whispers of Atabey – Wisdom of the Taíno Spirit</h1>
    <p class="subtitle">A digital Shaman sharing the wisdom of Taíno ancestors with 21st-century people</p>
    <button id="homeBtn"><span class="material-icons">home</span></button>
  </header>

  <section id="voiceChatPage">
    <div class="voice-wrapper">
      <p id="statusText">Hold to speak</p>
      <div id="orb" class="orb idle" role="button" tabindex="0" aria-label="Voice input button"></div>
      <div id="debugOutput"></div>
    </div>
  </section>

  <footer>
    <p>© 2025 Whispers of Atabey. All rights reserved.</p>
  </footer>

  <script>
    const orb = document.getElementById('orb');
    const statusText = document.getElementById('statusText');
    const debugOutput = document.getElementById('debugOutput');
    const audioPlayer = new Audio();

    let isRecording = false;
    let audioContext, analyser, dataArray, animationFrameId;
    let mediaRecorder, audioChunks = [];

    async function setupMicStream() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setupMicVisualizer(stream);
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = handleRecordingStop;
      mediaRecorder.start();
    }

    function setupMicVisualizer(stream) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 512;
      dataArray = new Uint8Array(analyser.frequencyBinCount);
      source.connect(analyser);
      animateOrb();
    }

    function animateOrb() {
      analyser.getByteFrequencyData(dataArray);
      const avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
      const scale = 1 + avg / 256;
      orb.style.transform = `scale(${scale.toFixed(2)})`;
      animationFrameId = requestAnimationFrame(animateOrb);
    }

    function stopVisualizer() {
      cancelAnimationFrame(animationFrameId);
      if (audioContext) audioContext.close();
      orb.style.transform = 'scale(1)';
    }

    async function handleRecordingStop() {
      stopVisualizer();
      orb.className = 'orb processing';
      statusText.textContent = 'Processing...';

      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      try {
        const transcriptRes = await fetch('http://localhost:5000/transcribe', { method: 'POST', body: formData });
        const transcriptData = await transcriptRes.json();

        const aiRes = await fetch('http://localhost:5000/ask', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ prompt: transcriptData.text })
        });
        const aiData = await aiRes.json();

        orb.className = 'orb speaking';
        statusText.textContent = 'Speaking...';
        debugOutput.textContent = `You said: "${transcriptData.text}"\nShaman: "${aiData.text}"`;

        audioPlayer.src = 'data:audio/mp3;base64,' + aiData.audio;
        audioPlayer.play();
        audioPlayer.onended = () => {
          orb.className = 'orb idle';
          statusText.textContent = 'Hold to speak';
        };
      } catch (err) {
        console.error('[Error]', err);
        statusText.textContent = 'Error during processing.';
        orb.className = 'orb idle';
      }
    }

    async function startVoiceInput(source = "UI or Arduino") {
      if (isRecording) return;
      isRecording = true;
      orb.className = 'orb recording';
      statusText.textContent = 'Recording... Speak now';

      try {
        await setupMicStream();
      } catch (err) {
        console.error('[Mic] Access error:', err);
        statusText.textContent = 'Mic access denied';
        orb.className = 'orb idle';
        isRecording = false;
      }
    }

    function stopVoiceInput() {
      if (!isRecording) return;
      isRecording = false;
      mediaRecorder.stop();
    }

    // Mouse & Touch
    orb.addEventListener('mousedown', () => startVoiceInput("orb"));
    orb.addEventListener('mouseup', stopVoiceInput);
    orb.addEventListener('touchstart', () => startVoiceInput("touch"));
    orb.addEventListener('touchend', stopVoiceInput);

    // Global Keyboard Trigger (works without clicking the orb)
    document.addEventListener('keydown', (e) => {
      if ((e.key === 'Enter' || e.key === ' ') && !isRecording) {
        e.preventDefault();
        startVoiceInput("keyboard");
      }
    });
    document.addEventListener('keyup', (e) => {
      if (e.key === 'Enter' || e.key === ' ') {
        stopVoiceInput();
      }
    });

    // WebSocket for Arduino or other remote triggers
    let socket;
    try {
      socket = new WebSocket(`ws://${location.hostname}:6789`);
    } catch (e) {
      console.error("[WebSocket] Failed to connect:", e);
    }

    if (socket) {
      socket.addEventListener("open", () => console.log("[WebSocket] Connected."));
      socket.addEventListener("message", (event) => {
        if (event.data === "trigger_voice") {
          startVoiceInput("arduino");
        }
      });
      socket.addEventListener("error", (error) => console.error("[WebSocket] Error:", error));
      socket.addEventListener("close", () => console.warn("[WebSocket] Connection closed."));
    }
  </script>
</body>
</html>
